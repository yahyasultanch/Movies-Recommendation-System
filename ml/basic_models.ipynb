{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-weight: bold;\">Initial Try - Basic Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from surprise import SVD, Dataset, Reader\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Elasticsearch\n",
    "\n",
    "es = Elasticsearch([\"http://localhost:9200\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yahya\\AppData\\Local\\Temp\\ipykernel_25280\\1787596816.py:11: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  resp = es.search(index=index_name, body=query, size=batch_size, scroll=\"2m\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating\n",
      "0   16140     3705     2.0\n",
      "1   16140     3717     5.0\n",
      "2   16140     3745     4.0\n",
      "3   16140     3751     3.0\n",
      "4   16140     3753     4.0\n"
     ]
    }
   ],
   "source": [
    "# Pull Ratings Data\n",
    "\n",
    "def fetch_all_ratings(es, index_name=\"ratings\", batch_size=10000):\n",
    "    \"\"\"\n",
    "    Example: a simple scroll to fetch all docs from 'ratings' index\n",
    "    \"\"\"\n",
    "    ratings = []\n",
    "    query = {\n",
    "        \"query\": {\"match_all\": {}}\n",
    "    }\n",
    "    resp = es.search(index=index_name, body=query, size=batch_size, scroll=\"2m\")\n",
    "    \n",
    "    scroll_id = resp[\"_scroll_id\"]\n",
    "    hits = resp[\"hits\"][\"hits\"]\n",
    "    \n",
    "    while len(hits) > 0:\n",
    "        for h in hits:\n",
    "            source = h[\"_source\"]\n",
    "            ratings.append({\n",
    "                \"userId\": source[\"userId\"],\n",
    "                \"movieId\": source[\"movieId\"],\n",
    "                \"rating\": source[\"rating\"]\n",
    "            })\n",
    "        resp = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "        scroll_id = resp[\"_scroll_id\"]\n",
    "        hits = resp[\"hits\"][\"hits\"]\n",
    "    \n",
    "    return pd.DataFrame(ratings)\n",
    "\n",
    "ratings_df = fetch_all_ratings(es, \"ratings\")\n",
    "print(ratings_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yahya\\AppData\\Local\\Temp\\ipykernel_25280\\1900206303.py:6: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  resp = es.search(index=index_name, body=query, size=batch_size, scroll=\"2m\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title               genres  \\\n",
      "0     3217              Star Is Born, A (1937)              [Drama]   \n",
      "1     3218                       Poison (1991)              [Drama]   \n",
      "2     3219              Pacific Heights (1990)  [Mystery, Thriller]   \n",
      "3     3220                   Night Tide (1961)              [Drama]   \n",
      "4     3221  Draughtsman's Contract, The (1982)              [Drama]   \n",
      "\n",
      "                                         description  popularity  vote_average  \n",
      "0  Esther Blodgett is just another starry-eyed fa...      13.408         7.200  \n",
      "1  A trio of interweaved transgressive tales, tel...       4.791         6.100  \n",
      "2  A couple works hard to renovate their dream ho...      13.862         6.200  \n",
      "3  A young sailor falls in love with a mysterious...       6.999         6.331  \n",
      "4  A young artist is commissioned by the wife of ...      13.244         7.100  \n"
     ]
    }
   ],
   "source": [
    "# Pull Movies Data\n",
    "\n",
    "def fetch_all_movies(es, index_name=\"movies\", batch_size=10000):\n",
    "    movies = []\n",
    "    query = {\"query\": {\"match_all\": {}}}\n",
    "    resp = es.search(index=index_name, body=query, size=batch_size, scroll=\"2m\")\n",
    "    \n",
    "    scroll_id = resp[\"_scroll_id\"]\n",
    "    hits = resp[\"hits\"][\"hits\"]\n",
    "    \n",
    "    while len(hits) > 0:\n",
    "        for h in hits:\n",
    "            source = h[\"_source\"]\n",
    "            # Extracting relevant fields\n",
    "            movies.append({\n",
    "                \"movieId\": int(source[\"movieId\"]) if \"movieId\" in source else None,\n",
    "                \"title\": source.get(\"title\",\"\"),\n",
    "                \"genres\": source.get(\"genres\", []),\n",
    "                \"description\": source.get(\"description\",\"\"),\n",
    "                \"popularity\": source.get(\"popularity\", 0.0),\n",
    "                \"vote_average\": source.get(\"vote_average\", 0.0)\n",
    "            })\n",
    "        resp = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "        scroll_id = resp[\"_scroll_id\"]\n",
    "        hits = resp[\"hits\"][\"hits\"]\n",
    "    \n",
    "    return pd.DataFrame(movies)\n",
    "\n",
    "movies_df = fetch_all_movies(es, \"movies\")\n",
    "print(movies_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving movies and ratings data in pickle object for later use. \n",
    "\n",
    "movies_df.to_pickle('movies.pkl')\n",
    "ratings_df.to_pickle('ratings.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Collaborative Filtering\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5.0))  \n",
    "data = Dataset.load_from_df(ratings_df[[\"userId\",\"movieId\",\"rating\"]], reader) \n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "algo = SVD(n_factors=50, reg_all=0.02)  # hyperparams\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 25         item: 247        r_ui = None   est = 3.64   {'was_impossible': False}\n",
      "Details for movieId 247:\n",
      "      movieId                      title          genres  \\\n",
      "9038      247  Heavenly Creatures (1994)  [Crime, Drama]   \n",
      "\n",
      "                                            description  popularity  \\\n",
      "9038  Precocious teenager Juliet moves to New Zealan...      13.149   \n",
      "\n",
      "      vote_average  \n",
      "9038         6.983  \n"
     ]
    }
   ],
   "source": [
    "# Example prediction for user=25, movie=247\n",
    "pred = algo.predict(uid=25, iid=247)\n",
    "print(pred) \n",
    "\n",
    "# Movie Data; which movie corresponds to movieId = 247\n",
    "movie_details = movies_df[movies_df[\"movieId\"] == 247]\n",
    "if not movie_details.empty:\n",
    "    print(f\"Details for movieId 247:\\n{movie_details}\")\n",
    "else:\n",
    "    print(\"movieId 247 not found in movies_df.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "> The value, \"est\", represents the system's estimate of how user 25 would rate movie 247, based on patterns learned from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD model saved as svd_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"svd_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(algo, f)\n",
    "\n",
    "print(\"SVD model saved as svd_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.7937  0.7932  0.7921  0.7927  0.7925  0.7929  0.0006  \n",
      "MAE (testset)     0.6010  0.6007  0.6000  0.6002  0.6001  0.6004  0.0004  \n",
      "Fit time          36.70   34.84   36.38   37.32   37.13   36.48   0.88    \n",
      "Test time         13.08   13.11   10.74   11.06   10.87   11.77   1.09    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.79369838, 0.79323965, 0.79206172, 0.79274328, 0.79250874]),\n",
       " 'test_mae': array([0.60100154, 0.6006687 , 0.59995719, 0.60019117, 0.6000727 ]),\n",
       " 'fit_time': (36.70147752761841,\n",
       "  34.839112281799316,\n",
       "  36.38200783729553,\n",
       "  37.3218879699707,\n",
       "  37.133997678756714),\n",
       " 'test_time': (13.078405141830444,\n",
       "  13.114790201187134,\n",
       "  10.735727548599243,\n",
       "  11.055685997009277,\n",
       "  10.867928981781006)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CF with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GridSearchCV to find optimal parameters for SVD...\n",
      "Best parameters found:\n",
      "{'n_factors': 150, 'reg_all': 0.05, 'lr_all': 0.01}\n",
      "Best RMSE: 0.7971\n",
      "Best SVD model saved as best_svd_model.pkl\n",
      "Prediction for user 25 and movie 247: 3.65\n",
      "Details for movieId 247:\n",
      "      movieId                      title          genres  \\\n",
      "9038      247  Heavenly Creatures (1994)  [Crime, Drama]   \n",
      "\n",
      "                                            description  popularity  \\\n",
      "9038  Precocious teenager Juliet moves to New Zealan...      13.149   \n",
      "\n",
      "      vote_average  \n",
      "9038         6.983  \n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5.0)) \n",
    "data = Dataset.load_from_df(ratings_df[[\"userId\", \"movieId\", \"rating\"]], reader)\n",
    "\n",
    "# parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    \"n_factors\": [50, 100, 150],      \n",
    "    \"reg_all\": [0.01, 0.02, 0.05],   \n",
    "    \"lr_all\": [0.005, 0.01, 0.05]   \n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "print(\"Starting GridSearchCV to find optimal parameters for SVD...\")\n",
    "grid_search = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3, n_jobs=-1)\n",
    "grid_search.fit(data)\n",
    "\n",
    "# Output the best parameters and RMSE\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params[\"rmse\"])\n",
    "print(f\"Best RMSE: {grid_search.best_score['rmse']:.4f}\")\n",
    "\n",
    "# Train the SVD model with best parameters\n",
    "best_params = grid_search.best_params[\"rmse\"]\n",
    "best_svd = SVD(**best_params)\n",
    "trainset = data.build_full_trainset()\n",
    "best_svd.fit(trainset)\n",
    "\n",
    "import pickle\n",
    "with open(\"best_svd_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_svd, f)\n",
    "print(\"Best SVD model saved as best_svd_model.pkl\")\n",
    "\n",
    "# Example prediction\n",
    "user_id = 25\n",
    "movie_id = 247\n",
    "pred = best_svd.predict(uid=user_id, iid=movie_id)\n",
    "print(f\"Prediction for user {user_id} and movie {movie_id}: {pred.est:.2f}\")\n",
    "\n",
    "# Check movie details for the given movie_id\n",
    "movie_details = movies_df[movies_df[\"movieId\"] == movie_id]\n",
    "if not movie_details.empty:\n",
    "    print(f\"Details for movieId {movie_id}:\\n{movie_details}\")\n",
    "else:\n",
    "    print(f\"movieId {movie_id} not found in movies_df.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No significant change observed using Grid Search. The initial self selected parameters gave quite similar results as compared to the optimal parameters selected via GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBF- Content Based Filtering (using simple TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using multi-hot encoding for genres and simple TF-IDF on description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Content Approach\n",
    "\n",
    "# computing a simple TF-IDF on \"description\" + multi-hot encode \"genres\"\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Multi-hot genres\n",
    "def multi_hot_genres(df, all_genres):\n",
    "    # all_genres: union set of all possible genres\n",
    "    out_df = df.copy()\n",
    "    for g in all_genres:\n",
    "        out_df[f\"genre_{g}\"] = out_df[\"genres\"].apply(lambda x: 1 if g in x else 0)\n",
    "    return out_df\n",
    "\n",
    "all_genre_set = set()\n",
    "for g_list in movies_df[\"genres\"]:\n",
    "    for g in g_list:\n",
    "        all_genre_set.add(g)\n",
    "\n",
    "movies_enriched = multi_hot_genres(movies_df, all_genre_set)\n",
    "\n",
    "# TF-IDF on description\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\", max_features=200)\n",
    "desc_matrix = tfidf.fit_transform(movies_enriched[\"description\"])\n",
    "\n",
    "# Combine TF-IDF matrix + genre multi-hot as a single vector\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "genre_cols = [c for c in movies_enriched.columns if c.startswith(\"genre_\")]\n",
    "genre_matrix = movies_enriched[genre_cols].values\n",
    "\n",
    "content_matrix = hstack([desc_matrix, genre_matrix])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature dimensions: 220\n",
      "Reduced feature dimensions: 220\n"
     ]
    }
   ],
   "source": [
    "# use if needed for saving computation and faster performance. (not used particularly here for now)\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "n_components = 220 \n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "content_matrix_reduced = svd.fit_transform(content_matrix)\n",
    "\n",
    "print(f\"Original feature dimensions: {content_matrix.shape[1]}\")\n",
    "print(f\"Reduced feature dimensions: {content_matrix_reduced.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_matrix_reduced = content_matrix_reduced.astype(np.float32)\n",
    "np.save(\"content_matrix_reduced.npy\", content_matrix_reduced)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors indexed: 62423\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "dim = content_matrix_reduced.shape[1]\n",
    "\n",
    "# Initialize FAISS index\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "\n",
    "# Normalize vectors to unit length for cosine similarity\n",
    "faiss.normalize_L2(content_matrix_reduced)\n",
    "index.add(content_matrix_reduced)\n",
    "\n",
    "print(f\"Number of vectors indexed: {index.ntotal}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Find top-5 similar movies to the 10th movie in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Movie - MovieID: 3227, Title: Not Love, Just Frenzy (Más que amor, frenesí) (1996)\n",
      "MovieID: 160434, Title: Doc Martin (2001), Similarity Score: 0.8660\n",
      "MovieID: 104451, Title: Dealing: Or the Berkeley-to-Boston Forty-Brick Lost-Bag Blues (1972), Similarity Score: 0.8660\n",
      "MovieID: 54988, Title: Stories of Lost Souls (2005), Similarity Score: 0.8660\n",
      "MovieID: 166996, Title: Miedo a salir de noche (1980), Similarity Score: 0.8353\n",
      "MovieID: 109, Title: Headless Body in Topless Bar (1995), Similarity Score: 0.8146\n"
     ]
    }
   ],
   "source": [
    "i = 10  \n",
    "k = 5   \n",
    "\n",
    "query_vector = content_matrix_reduced[i].reshape(1, -1)\n",
    "distances, indices = index.search(query_vector, k + 1) \n",
    "\n",
    "movie_id = movies_df.iloc[i][\"movieId\"]\n",
    "title = movies_df.iloc[i][\"title\"]\n",
    "print(f\"Query Movie - MovieID: {movie_id}, Title: {title}\")\n",
    "\n",
    "similar_movie_indices = indices[0][1:]\n",
    "similar_distances = distances[0][1:]\n",
    "\n",
    "# Map indices back to movie IDs and titles\n",
    "for idx, dist in zip(similar_movie_indices, similar_distances):\n",
    "    movie_id = movies_df.iloc[idx][\"movieId\"]\n",
    "    title = movies_df.iloc[idx][\"title\"]\n",
    "    print(f\"MovieID: {movie_id}, Title: {title}, Similarity Score: {dist:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "> queried the system to find similar movies to the 10th movie in the DataFrame.\n",
    "\n",
    "> system identified the movies listed above as the closest matches to the query movie\n",
    "\n",
    "> The similarity score ranges from 0 to 1 (closer to 1 indicates higher similarity).\n",
    "\n",
    "The model is finding 'similarity' based on simple encodings and we aren't capturing any sementic context here hence the simplicity is a trade-off with performance. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarities for Retrieved Movies: [0.8660256 0.8660256 0.8660256 0.8353237 0.8146171]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query_vector = content_matrix_reduced[i].reshape(1, -1)\n",
    "similar_vectors = content_matrix_reduced[similar_movie_indices]\n",
    "cosine_similarities = cosine_similarity(query_vector, similar_vectors)\n",
    "\n",
    "print(\"Cosine Similarities for Retrieved Movies:\", cosine_similarities[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index saved as faiss_index.index\n"
     ]
    }
   ],
   "source": [
    "faiss.write_index(index, \"faiss_index.index\")\n",
    "print(\"FAISS index saved as faiss_index.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Approach - Combining Collaborative Filtering with Content Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_hybrid_recommendations(user_id, movie_id, cf_algo, faiss_index, movies_df, content_matrix_reduced, top_k=5, alpha=0.7):\n",
    "    \"\"\"\n",
    "    Combining CF and CBF to generate hybrid recommendations.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_id: ID of the user\n",
    "    - movie_id: ID of the movie to find recommendations similar to\n",
    "    - cf_algo: Trained CF algorithm \n",
    "    - faiss_index: FAISS index for CBF\n",
    "    - movies_df: DataFrame containing movie metadata\n",
    "    - content_matrix_reduced: Numpy array of reduced content features\n",
    "    - top_k: Number of recommendations to return\n",
    "    - alpha: Weight for CF scores (1 - alpha for CBF)\n",
    "    \n",
    "    Returns:\n",
    "    - List of recommended movie titles with combined scores\n",
    "    \"\"\"\n",
    "    # Collaborative Filtering Score\n",
    "    cf_pred = cf_algo.predict(uid=user_id, iid=movie_id)\n",
    "    cf_score = cf_pred.est  # Estimated rating\n",
    "    \n",
    "    # Content-Based Similarity\n",
    "    try:\n",
    "        movie_idx = movies_df[movies_df[\"movieId\"] == movie_id].index[0]\n",
    "    except IndexError:\n",
    "        print(f\"MovieID {movie_id} not found in movies_df.\")\n",
    "        return []\n",
    "    \n",
    "    query_vector = content_matrix_reduced[movie_idx].reshape(1, -1)\n",
    "    faiss.normalize_L2(query_vector)\n",
    "    \n",
    "    distances, indices = faiss_index.search(query_vector, top_k + 1)\n",
    "    \n",
    "    similar_movie_indices = indices[0][1:] \n",
    "    similar_distances = distances[0][1:]\n",
    "    \n",
    "    # Compute similarity scores (higher is better)\n",
    "    similarity_scores = 1 - similar_distances \n",
    "    \n",
    "    # Combine CF and CBF Scores\n",
    "    combined_scores = alpha * cf_score + (1 - alpha) * similarity_scores\n",
    "    \n",
    "    recommendations = []\n",
    "    for idx, score in zip(similar_movie_indices, combined_scores):\n",
    "        recommended_movie_id = movies_df.iloc[idx][\"movieId\"]\n",
    "        recommended_title = movies_df.iloc[idx][\"title\"]\n",
    "        recommendations.append({\n",
    "            \"movieId\": recommended_movie_id,\n",
    "            \"title\": recommended_title,\n",
    "            \"combined_score\": score\n",
    "        })\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieID: 5748, Title: Inquisitor, The (a.k.a. Under Suspicion) (Garde à vue) (1981), Combined Score: 2.6634\n",
      "MovieID: 168330, Title: I Don't Feel at Home in This World Anymore (2017), Combined Score: 2.6707\n",
      "MovieID: 146472, Title: Duffy of San Quentin (1954), Combined Score: 2.6771\n",
      "MovieID: 37741, Title: Capote (2005), Combined Score: 2.6771\n",
      "MovieID: 34238, Title: Symmetry (Symetria) (2003), Combined Score: 2.6779\n"
     ]
    }
   ],
   "source": [
    "user_id = 25\n",
    "movie_id = 247  \n",
    "recommendations = get_hybrid_recommendations(user_id, movie_id, algo, index, movies_df, content_matrix_reduced, top_k=5, alpha=0.7)\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(f\"MovieID: {rec['movieId']}, Title: {rec['title']}, Combined Score: {rec['combined_score']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

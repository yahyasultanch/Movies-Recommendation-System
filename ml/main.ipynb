{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from surprise import SVD, Dataset, Reader\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# 1) Connect to Elasticsearch\n",
    "#####################################\n",
    "es = Elasticsearch([\"http://localhost:9200\"])  # or \"http://127.0.0.1:9200\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yahya\\AppData\\Local\\Temp\\ipykernel_19320\\3946218915.py:12: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  resp = es.search(index=index_name, body=query, size=batch_size, scroll=\"2m\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating\n",
      "0   16140     3705     2.0\n",
      "1   16140     3717     5.0\n",
      "2   16140     3745     4.0\n",
      "3   16140     3751     3.0\n",
      "4   16140     3753     4.0\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# 2) Pull Ratings Data\n",
    "#####################################\n",
    "def fetch_all_ratings(es, index_name=\"ratings\", batch_size=10000):\n",
    "    \"\"\"\n",
    "    Example: a simple scroll to fetch all docs from 'ratings' index\n",
    "    \"\"\"\n",
    "    ratings = []\n",
    "    query = {\n",
    "        \"query\": {\"match_all\": {}}\n",
    "    }\n",
    "    resp = es.search(index=index_name, body=query, size=batch_size, scroll=\"2m\")\n",
    "    \n",
    "    scroll_id = resp[\"_scroll_id\"]\n",
    "    hits = resp[\"hits\"][\"hits\"]\n",
    "    \n",
    "    while len(hits) > 0:\n",
    "        for h in hits:\n",
    "            source = h[\"_source\"]\n",
    "            # userId, movieId, rating\n",
    "            ratings.append({\n",
    "                \"userId\": source[\"userId\"],\n",
    "                \"movieId\": source[\"movieId\"],\n",
    "                \"rating\": source[\"rating\"]\n",
    "            })\n",
    "        resp = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "        scroll_id = resp[\"_scroll_id\"]\n",
    "        hits = resp[\"hits\"][\"hits\"]\n",
    "    \n",
    "    return pd.DataFrame(ratings)\n",
    "\n",
    "ratings_df = fetch_all_ratings(es, \"ratings\")\n",
    "print(ratings_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yahya\\AppData\\Local\\Temp\\ipykernel_19320\\3724352756.py:7: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  resp = es.search(index=index_name, body=query, size=batch_size, scroll=\"2m\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title               genres  \\\n",
      "0     3217              Star Is Born, A (1937)              [Drama]   \n",
      "1     3218                       Poison (1991)              [Drama]   \n",
      "2     3219              Pacific Heights (1990)  [Mystery, Thriller]   \n",
      "3     3220                   Night Tide (1961)              [Drama]   \n",
      "4     3221  Draughtsman's Contract, The (1982)              [Drama]   \n",
      "\n",
      "                                         description  popularity  vote_average  \n",
      "0  Esther Blodgett is just another starry-eyed fa...      13.408         7.200  \n",
      "1  A trio of interweaved transgressive tales, tel...       4.791         6.100  \n",
      "2  A couple works hard to renovate their dream ho...      13.862         6.200  \n",
      "3  A young sailor falls in love with a mysterious...       6.999         6.331  \n",
      "4  A young artist is commissioned by the wife of ...      13.244         7.100  \n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# 3) Pull Movies Data\n",
    "#####################################\n",
    "def fetch_all_movies(es, index_name=\"movies\", batch_size=10000):\n",
    "    movies = []\n",
    "    query = {\"query\": {\"match_all\": {}}}\n",
    "    resp = es.search(index=index_name, body=query, size=batch_size, scroll=\"2m\")\n",
    "    \n",
    "    scroll_id = resp[\"_scroll_id\"]\n",
    "    hits = resp[\"hits\"][\"hits\"]\n",
    "    \n",
    "    while len(hits) > 0:\n",
    "        for h in hits:\n",
    "            source = h[\"_source\"]\n",
    "            # Extract relevant fields\n",
    "            movies.append({\n",
    "                \"movieId\": int(source[\"movieId\"]) if \"movieId\" in source else None,\n",
    "                \"title\": source.get(\"title\",\"\"),\n",
    "                \"genres\": source.get(\"genres\", []),\n",
    "                \"description\": source.get(\"description\",\"\"),\n",
    "                \"popularity\": source.get(\"popularity\", 0.0),\n",
    "                \"vote_average\": source.get(\"vote_average\", 0.0)\n",
    "            })\n",
    "        resp = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "        scroll_id = resp[\"_scroll_id\"]\n",
    "        hits = resp[\"hits\"][\"hits\"]\n",
    "    \n",
    "    return pd.DataFrame(movies)\n",
    "\n",
    "movies_df = fetch_all_movies(es, \"movies\")\n",
    "print(movies_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 25         item: 247        r_ui = None   est = 3.75   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# 4) Basic Collaborative Filtering\n",
    "#####################################\n",
    "# Surprise requires (user, item, rating)\n",
    "reader = Reader(rating_scale=(0.5, 5.0))  # or (0,5) depending on dataset\n",
    "data = Dataset.load_from_df(ratings_df[[\"userId\",\"movieId\",\"rating\"]], reader)\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "algo = SVD(n_factors=50, reg_all=0.02)  # example hyperparams\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Example prediction for user=25, movie=247\n",
    "pred = algo.predict(uid=25, iid=247)\n",
    "print(pred)  # gives a rating estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This value, 3.58, represents the system's estimate of how user 25 would rate movie 247, based on patterns learned from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# 5) Content/Hybrid Approach\n",
    "#####################################\n",
    "# a) For each movie, build a content vector (genres + optional text from 'description')\n",
    "# b) For each user, you can do user-based CF or combine user’s CF-based latent vector \n",
    "#    with content similarities.\n",
    "\n",
    "# Example: Just compute a simple TF-IDF on \"description\" + multi-hot encode \"genres\"\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Multi-hot genres\n",
    "def multi_hot_genres(df, all_genres):\n",
    "    # all_genres: union set of all possible genres\n",
    "    # returns a DataFrame with genre_ columns\n",
    "    out_df = df.copy()\n",
    "    for g in all_genres:\n",
    "        out_df[f\"genre_{g}\"] = out_df[\"genres\"].apply(lambda x: 1 if g in x else 0)\n",
    "    return out_df\n",
    "\n",
    "all_genre_set = set()\n",
    "for g_list in movies_df[\"genres\"]:\n",
    "    for g in g_list:\n",
    "        all_genre_set.add(g)\n",
    "\n",
    "movies_enriched = multi_hot_genres(movies_df, all_genre_set)\n",
    "\n",
    "# Simple TF-IDF on description\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\", max_features=200)\n",
    "desc_matrix = tfidf.fit_transform(movies_enriched[\"description\"])\n",
    "\n",
    "# Combine TF-IDF matrix + genre multi-hot as a single vector\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "genre_cols = [c for c in movies_enriched.columns if c.startswith(\"genre_\")]\n",
    "genre_matrix = movies_enriched[genre_cols].values  # shape: (num_movies, num_genres)\n",
    "\n",
    "content_matrix = hstack([desc_matrix, genre_matrix])  # shape: (num_movies, 200 + num_genres)\n",
    "\n",
    "# Now 'content_matrix' is a feature vector for each movie\n",
    "# You can compute item-item similarity or incorporate this into a hybrid model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature dimensions: 220\n",
      "Reduced feature dimensions: 110\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Apply TruncatedSVD to reduce dimensions\n",
    "n_components = 110  # Adjust based on your dataset and performance\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "content_matrix_reduced = svd.fit_transform(content_matrix)\n",
    "\n",
    "print(f\"Original feature dimensions: {content_matrix.shape[1]}\")\n",
    "print(f\"Reduced feature dimensions: {content_matrix_reduced.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_matrix_reduced = content_matrix_reduced.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors indexed: 62423\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# Define dimensions after TruncatedSVD\n",
    "dim = content_matrix_reduced.shape[1]\n",
    "\n",
    "# Initialize FAISS index\n",
    "# 'IndexFlatIP' uses inner product, suitable for cosine similarity when vectors are normalized\n",
    "index = faiss.IndexFlatIP(dim)\n",
    "\n",
    "# Normalize vectors to unit length for cosine similarity\n",
    "faiss.normalize_L2(content_matrix_reduced)\n",
    "\n",
    "# Add vectors to the index\n",
    "index.add(content_matrix_reduced)\n",
    "\n",
    "print(f\"Number of vectors indexed: {index.ntotal}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Movie - MovieID: 3227, Title: Not Love, Just Frenzy (Más que amor, frenesí) (1996)\n",
      "MovieID: 160434, Title: Doc Martin (2001), Similarity Score: 0.9145\n",
      "MovieID: 104451, Title: Dealing: Or the Berkeley-to-Boston Forty-Brick Lost-Bag Blues (1972), Similarity Score: 0.9145\n",
      "MovieID: 54988, Title: Stories of Lost Souls (2005), Similarity Score: 0.9145\n",
      "MovieID: 109, Title: Headless Body in Topless Bar (1995), Similarity Score: 0.9019\n",
      "MovieID: 204438, Title: Gone with the Woman (2007), Similarity Score: 0.8865\n"
     ]
    }
   ],
   "source": [
    "# Example: Find top-5 similar movies to the 10th movie in the DataFrame\n",
    "i = 10  # Movie index in the DataFrame\n",
    "k = 5   # Number of similar movies to retrieve\n",
    "\n",
    "# Retrieve the vector for movie i\n",
    "query_vector = content_matrix_reduced[i].reshape(1, -1)\n",
    "\n",
    "# Perform the search\n",
    "distances, indices = index.search(query_vector, k + 1)  # k+1 because the first result is the movie itself\n",
    "\n",
    "# Print the details of the movie at index i\n",
    "movie_id = movies_df.iloc[i][\"movieId\"]\n",
    "title = movies_df.iloc[i][\"title\"]\n",
    "print(f\"Query Movie - MovieID: {movie_id}, Title: {title}\")\n",
    "\n",
    "# Exclude the first result (the movie itself)\n",
    "similar_movie_indices = indices[0][1:]\n",
    "similar_distances = distances[0][1:]\n",
    "\n",
    "# Map indices back to movie IDs and titles\n",
    "for idx, dist in zip(similar_movie_indices, similar_distances):\n",
    "    movie_id = movies_df.iloc[idx][\"movieId\"]\n",
    "    title = movies_df.iloc[idx][\"title\"]\n",
    "    print(f\"MovieID: {movie_id}, Title: {title}, Similarity Score: {dist:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queried the system to find similar movies to the 10th movie in the DataFrame.\n",
    "#  system identified the movies listed above as the closest matches to the query movie\n",
    "# The similarity score ranges from 0 to 1 (closer to 1 indicates higher similarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieID: 5748, Title: Inquisitor, The (a.k.a. Under Suspicion) (Garde à vue) (1981), Combined Score: 2.6595\n",
      "MovieID: 1221, Title: Godfather: Part II, The (1974), Combined Score: 2.6626\n",
      "MovieID: 87042, Title: Wanda (1970), Combined Score: 2.6672\n",
      "MovieID: 130912, Title: In the Shadow (2012), Combined Score: 2.6678\n",
      "MovieID: 1804, Title: Newton Boys, The (1998), Combined Score: 2.6694\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Collaborative Filtering (CF) - Already Built\n",
    "# ratings_df = fetch_all_ratings(es, \"ratings\")\n",
    "# CF model: 'algo'\n",
    "\n",
    "# 2. Content-Based Filtering (CBF) - FAISS Index Built\n",
    "# movies_df = fetch_all_movies(es, \"movies\")\n",
    "# FAISS index: 'index'\n",
    "\n",
    "# 3. Hybrid Recommendation Function\n",
    "def get_hybrid_recommendations(user_id, movie_id, cf_algo, faiss_index, movies_df, content_matrix_reduced, top_k=5, alpha=0.7):\n",
    "    \"\"\"\n",
    "    Combine CF and CBF to generate hybrid recommendations.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_id: ID of the user\n",
    "    - movie_id: ID of the movie to find recommendations similar to\n",
    "    - cf_algo: Trained CF algorithm (e.g., SVD)\n",
    "    - faiss_index: FAISS index for CBF\n",
    "    - movies_df: DataFrame containing movie metadata\n",
    "    - content_matrix_reduced: Numpy array of reduced content features\n",
    "    - top_k: Number of recommendations to return\n",
    "    - alpha: Weight for CF scores (1 - alpha for CBF)\n",
    "    \n",
    "    Returns:\n",
    "    - List of recommended movie titles with combined scores\n",
    "    \"\"\"\n",
    "    # 1. Collaborative Filtering Score\n",
    "    cf_pred = cf_algo.predict(uid=user_id, iid=movie_id)\n",
    "    cf_score = cf_pred.est  # Estimated rating\n",
    "    \n",
    "    # 2. Content-Based Similarity\n",
    "    # Find the index of the movie_id in movies_df\n",
    "    try:\n",
    "        movie_idx = movies_df[movies_df[\"movieId\"] == movie_id].index[0]\n",
    "    except IndexError:\n",
    "        print(f\"MovieID {movie_id} not found in movies_df.\")\n",
    "        return []\n",
    "    \n",
    "    query_vector = content_matrix_reduced[movie_idx].reshape(1, -1)\n",
    "    faiss.normalize_L2(query_vector)\n",
    "    \n",
    "    distances, indices = faiss_index.search(query_vector, top_k + 1)\n",
    "    \n",
    "    similar_movie_indices = indices[0][1:]  # Exclude itself\n",
    "    similar_distances = distances[0][1:]\n",
    "    \n",
    "    # Compute similarity scores (higher is better)\n",
    "    similarity_scores = 1 - similar_distances  # Since 'angular' distance correlates with cosine similarity\n",
    "    \n",
    "    # 3. Combine CF and CBF Scores\n",
    "    combined_scores = alpha * cf_score + (1 - alpha) * similarity_scores\n",
    "    \n",
    "    recommendations = []\n",
    "    for idx, score in zip(similar_movie_indices, combined_scores):\n",
    "        recommended_movie_id = movies_df.iloc[idx][\"movieId\"]\n",
    "        recommended_title = movies_df.iloc[idx][\"title\"]\n",
    "        recommendations.append({\n",
    "            \"movieId\": recommended_movie_id,\n",
    "            \"title\": recommended_title,\n",
    "            \"combined_score\": score\n",
    "        })\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Example Usage\n",
    "user_id = 25\n",
    "movie_id = 247  # Replace with a valid movie ID from your dataset\n",
    "recommendations = get_hybrid_recommendations(user_id, movie_id, algo, index, movies_df, content_matrix_reduced, top_k=5, alpha=0.7)\n",
    "\n",
    "for rec in recommendations:\n",
    "    print(f\"MovieID: {rec['movieId']}, Title: {rec['title']}, Combined Score: {rec['combined_score']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

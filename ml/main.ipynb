{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-weight: bold;\">Advanced Content-Based Filtering Model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> using deep embeddings for movie descriptions and genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from elasticsearch import Elasticsearch\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/mnt/c/Users/UserName/Documents/Directory/Movies-Recommendation-System/ml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Elasticsearch\n",
    "es = Elasticsearch([\"http://localhost:9200\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_221986/3320190023.py:5: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  resp = es.search(index=index_name, body=query, size=batch_size, scroll=\"2m\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded movies data successfully.\n"
     ]
    }
   ],
   "source": [
    "# Fetch Movies Data from Elasticsearch\n",
    "def fetch_all_movies(es, index_name=\"movies\", batch_size=10000):\n",
    "    movies = []\n",
    "    query = {\"query\": {\"match_all\": {}}}\n",
    "    resp = es.search(index=index_name, body=query, size=batch_size, scroll=\"2m\")\n",
    "    \n",
    "    scroll_id = resp[\"_scroll_id\"]\n",
    "    hits = resp[\"hits\"][\"hits\"]\n",
    "    \n",
    "    while len(hits) > 0:\n",
    "        for h in hits:\n",
    "            source = h[\"_source\"]\n",
    "            movies.append({\n",
    "                \"movieId\": int(source[\"movieId\"]) if \"movieId\" in source else None,\n",
    "                \"title\": source.get(\"title\", \"\"),\n",
    "                \"genres\": source.get(\"genres\", []),\n",
    "                \"description\": source.get(\"description\", \"\"),\n",
    "                \"popularity\": source.get(\"popularity\", 0.0),\n",
    "                \"vote_average\": source.get(\"vote_average\", 0.0)\n",
    "            })\n",
    "        resp = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "        scroll_id = resp[\"_scroll_id\"]\n",
    "        hits = resp[\"hits\"][\"hits\"]\n",
    "    \n",
    "    return pd.DataFrame(movies)\n",
    "\n",
    "movies_df = fetch_all_movies(es, \"movies\")\n",
    "print(\"Loaded movies data successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.to_pickle('movies.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> SentenceTransformer (Pre-trained on language task; all-MiniLM-L6-v2).\n",
    "- Encodes textual descriptions of movies into high-dimensional numerical vectors (dense embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Description Embeddings\n",
    "if 'desc_embedding' not in movies_df.columns:\n",
    "    print(\"Generating description embeddings using SentenceTransformers...\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight pre-trained model\n",
    "    movies_df['desc_embedding'] = movies_df['description'].apply(\n",
    "        lambda x: model.encode(x, show_progress_bar=False) if pd.notnull(x) else np.zeros(384)\n",
    "    )\n",
    "else:\n",
    "    print(\"'desc_embedding' already exists in movies_df.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Genre Embeddings\n",
    "if 'genre_embedding' not in movies_df.columns:\n",
    "    print(\"Generating genre embeddings...\")\n",
    "    genre_set = set([genre for genres in movies_df['genres'] for genre in genres])\n",
    "    genre_list = sorted(genre_set)\n",
    "    genre_to_idx = {genre: idx for idx, genre in enumerate(genre_list)}\n",
    "\n",
    "    def genre_to_embedding(genres):\n",
    "        genre_vec = np.zeros(len(genre_list), dtype=np.float32)\n",
    "        for genre in genres:\n",
    "            if genre in genre_to_idx:\n",
    "                genre_vec[genre_to_idx[genre]] = 1.0\n",
    "        return genre_vec\n",
    "\n",
    "    movies_df['genre_embedding'] = movies_df['genres'].apply(genre_to_embedding)\n",
    "else:\n",
    "    print(\"'genre_embedding' already exists in movies_df.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Description and Genre Embeddings\n",
    "print(\"Combining description and genre embeddings...\")\n",
    "def combine_embeddings(row):\n",
    "    desc_embed = np.array(row['desc_embedding'])\n",
    "    genre_embed = np.array(row['genre_embedding'])\n",
    "    return np.concatenate((desc_embed, genre_embed))\n",
    "\n",
    "if 'combined_embedding' not in movies_df.columns:\n",
    "    movies_df['combined_embedding'] = movies_df.apply(combine_embeddings, axis=1)\n",
    "else:\n",
    "    print(\"'combined_embedding' already exists in movies_df.\")\n",
    "\n",
    "# Prepare the embedding matrix for FAISS\n",
    "print(\"Preparing the embedding matrix...\")\n",
    "embedding_matrix = np.vstack(movies_df['combined_embedding'].values).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS Index\n",
    "print(\"Creating FAISS index...\")\n",
    "dim = embedding_matrix.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)  # Inner Product for cosine similarity\n",
    "faiss.normalize_L2(embedding_matrix)  # Normalize vectors to unit length\n",
    "index.add(embedding_matrix)\n",
    "print(f\"FAISS index created with {index.ntotal} vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_220169/3158370973.py:15: DeprecationWarning: Received 'size' via a specific parameter in the presence of a 'body' parameter, which is deprecated and will be removed in a future version. Instead, use only 'body' or only specific parameters.\n",
      "  resp = es.search(index=index_name, body=query, size=batch_size, scroll=\"2m\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded movies data successfully.\n",
      "Generating description embeddings using SentenceTransformers...\n",
      "Generating genre embeddings...\n",
      "Combining description and genre embeddings...\n",
      "Preparing the embedding matrix...\n",
      "Creating FAISS index...\n",
      "FAISS index created with 62423 vectors.\n",
      "Saving model components for future use...\n",
      "All components saved successfully.\n",
      "Top 5 recommendations for 'Heavenly Creatures (1994)':\n",
      "1. Swimming Pool, The (La piscine) (1969) (Similarity Score: 0.8527)\n",
      "2. Best Laid Plans (1999) (Similarity Score: 0.8174)\n",
      "3. Whistle Stop (1946) (Similarity Score: 0.8136)\n",
      "4. Buster and Billie (1974) (Similarity Score: 0.8134)\n",
      "5. The Amy Fisher Story (1993) (Similarity Score: 0.8095)\n"
     ]
    }
   ],
   "source": [
    "# Saving Model Components\n",
    "print(\"Saving model components for future use...\")\n",
    "movies_df.to_pickle('movies_with_embeddings.pkl')  # Movies with embeddings\n",
    "faiss.write_index(index, 'faiss_index.bin')        # FAISS index\n",
    "np.save(\"content_matrix_reduced.npy\", embedding_matrix)  # Embedding matrix\n",
    "with open('genre_to_idx.pkl', 'wb') as f:          # Genre mapping\n",
    "    pickle.dump(genre_to_idx, f)\n",
    "\n",
    "if (os.path.exists('movies_with_embeddings.pkl') and \n",
    "    os.path.exists('faiss_index.bin') and \n",
    "    os.path.exists('content_matrix_reduced.npy') and \n",
    "    os.path.exists('genre_to_idx.pkl')):\n",
    "    print(\"All components saved successfully.\")\n",
    "else:\n",
    "    print(\"Error: Some components were not saved properly.\")\n",
    "\n",
    "\n",
    "### Example Recommendation Function\n",
    "def recommend_movies(movie_title, movies_df, index, k=5):\n",
    "    # Find the query movie\n",
    "    try:\n",
    "        query_idx = movies_df[movies_df['title'] == movie_title].index[0]\n",
    "    except IndexError:\n",
    "        print(f\"Movie '{movie_title}' not found in the dataset.\")\n",
    "        return []\n",
    "\n",
    "    query_vector = embedding_matrix[query_idx].reshape(1, -1)\n",
    "    faiss.normalize_L2(query_vector)\n",
    "\n",
    "    # Perform the search\n",
    "    distances, indices = index.search(query_vector, k + 1)  # k+1 because the first result is the movie itself\n",
    "\n",
    "    similar_movie_indices = indices[0][1:]\n",
    "    similar_distances = distances[0][1:]\n",
    "\n",
    "    # Map indices back to movie titles\n",
    "    recommendations = []\n",
    "    for idx, dist in zip(similar_movie_indices, similar_distances):\n",
    "        recommended_movie = movies_df.iloc[idx]\n",
    "        recommendations.append((recommended_movie['title'], dist))\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# Testing the Recommendation System\n",
    "test_movie = \"Heavenly Creatures (1994)\" \n",
    "recommendations = recommend_movies(test_movie, movies_df, index, k=5)\n",
    "\n",
    "if recommendations:\n",
    "    print(f\"Top 5 recommendations for '{test_movie}':\")\n",
    "    for i, (title, score) in enumerate(recommendations, start=1):\n",
    "        print(f\"{i}. {title} (Similarity Score: {score:.4f})\")\n",
    "else:\n",
    "    print(\"No recommendations found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
